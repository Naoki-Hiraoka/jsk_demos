<launch>
  <node pkg="uvc_camera" type="uvc_camera_node" name="camera_driver" />
  <!-- <node pkg="image_proc" type="image_proc" name="image_proc" > -->
  <!--   <remap from="image" to="image_raw" /> -->
  <!-- </node> -->
  
  <node name="image_publisher" pkg="jsk_perception" type="image_publisher.py">
    <rosparam subst_value="true">
    file_name: $(find hiraoka_semi)/image/head_img1.jpg
    rate: 30
    </rosparam>
  </node>

  <node name="image_siftnode" pkg="imagesift" type="imagesift"
	output="screen" >
    <remap from="image" to="image_publisher/output" />
  </node>

  <node name="point_pose_extractor" pkg="jsk_perception"
	type="point_pose_extractor">
    <param name="child_frame_name" value="opencv_logo"/>
    <param name="template_filename" value="$(find hiraoka_semi)/image/head_img1_part0.jpg"/>
    <param name="object_width" value="0.10" />
    <param name="object_height" value="0.20" />
    <param name="reprojection_threshold" value="10.0" />  <!-- 3.0 -->
    <param name="distanceratio_threshold" value="0.60" /> <!-- 0.49 -->
	<!--param name="relative_pose" value="0 0 0 0 0 0 1" /-->    <!-- quaternion expression -->
	<param name="relative_pose" value="0 0 0 0 0 0" /> <!-- you can also use rpy expression. --> -->
    <param name="error_threshold" value="5.0" />
    <param name="viewer_window" value="true" />
  </node>

  <sphinxdoc><![CDATA[
This script starts sift base object pose detection node.
defualt template image is `opencv logo <http://www.google.com/search?client=ubuntu&channel=fs&q=opencv&oe=utf-8&um=1&ie=UTF-8&tbm=isch&source=og&sa=N&hl=ja&tab=wi&biw=937&bih=638>`_.

.. code-block:: bash

  rosrun roseus_tutorial point-pose-extraction.l

to read the result data from euslisp program.
you need to launch image-view.launch before using this sample.
  ]]></sphinxdoc>

</launch>
